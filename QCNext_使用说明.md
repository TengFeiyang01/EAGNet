# QCNext: è”åˆå¤šæ™ºèƒ½ä½“è½¨è¿¹é¢„æµ‹æ¡†æ¶

## ğŸ“‹ æ¦‚è¿°

QCNextæ˜¯QCNetçš„å‡çº§ç‰ˆæœ¬ï¼Œå®ç°äº†ä»**è¾¹é™…è½¨è¿¹é¢„æµ‹**åˆ°**è”åˆå¤šæ™ºèƒ½ä½“è½¨è¿¹é¢„æµ‹**çš„é‡å¤§è·ƒè¿›ã€‚

### ğŸ†š QCNet vs QCNext å¯¹æ¯”

| ç‰¹æ€§ | QCNet | QCNext |
|------|-------|--------|
| **é¢„æµ‹ç±»å‹** | è¾¹é™…é¢„æµ‹ï¼ˆæ¯ä¸ªæ™ºèƒ½ä½“ç‹¬ç«‹ï¼‰ | è”åˆé¢„æµ‹ï¼ˆåœºæ™¯çº§æ•´ä½“ï¼‰ |
| **è§£ç å™¨æ¶æ„** | é€’å½’è§£ç å™¨ | Multi-Agent DETR-likeè§£ç å™¨ |
| **äº¤äº’å»ºæ¨¡** | éšå¼ï¼ˆA2A attentionï¼‰ | æ˜¾å¼ï¼ˆæœªæ¥æ—¶åˆ»äº¤äº’ï¼‰ |
| **è¾“å‡ºæ ¼å¼** | [A, M, T, D] | [K, A, T, D] |
| **æŸå¤±å‡½æ•°** | æ™ºèƒ½ä½“çº§NLL | åœºæ™¯çº§Winner-Take-All |
| **è¯„åˆ†æœºåˆ¶** | å•æ™ºèƒ½ä½“ç½®ä¿¡åº¦ | åœºæ™¯çº§ç½®ä¿¡åº¦ |

## ğŸ—ï¸ æ ¸å¿ƒæ¶æ„

### 1. **Anchor-Free Trajectory Proposal Module**
```python
# Kä¸ªè”åˆåœºæ™¯æŸ¥è¯¢ [K, A, D]
joint_mode_queries = nn.Parameter(torch.randn(K, max_agents, hidden_dim))

# å››ç§æ³¨æ„åŠ›æœºåˆ¶
- Mode2Time cross-attention    # ä¸å†å²æ—¶åºäº¤äº’
- Mode2Map cross-attention     # ä¸åœ°å›¾ä¿¡æ¯äº¤äº’  
- Row-wise self-attention      # åŒåœºæ™¯å†…æ™ºèƒ½ä½“äº¤äº’
- Column-wise self-attention   # ä¸åŒåœºæ™¯é—´é€šä¿¡
```

### 2. **Anchor-Based Trajectory Refinement Module**
```python
# åŸºäºproposalç»“æœè¿›è¡Œç²¾åŒ–
traj_emb = nn.GRU(...)  # è½¨è¿¹åµŒå…¥
# ç›¸åŒçš„å››ç§æ³¨æ„åŠ›æœºåˆ¶è¿›è¡Œrefinement
```

### 3. **Scene Scoring Module**
```python
# åœºæ™¯çº§ç½®ä¿¡åº¦è¯„åˆ†
scene_scoring = nn.Sequential(
    nn.Linear(hidden_dim, hidden_dim),
    nn.ReLU(),
    nn.Linear(hidden_dim, 1)
)
```

## ğŸ“Š æŸå¤±å‡½æ•°

### Joint NLL Loss (è”åˆè´Ÿå¯¹æ•°ä¼¼ç„¶æŸå¤±)
```python
# åœºæ™¯çº§Winner-Take-Allç­–ç•¥
def forward(pred, target, mask):
    # pred: [K, A, T, D] - Kä¸ªè”åˆåœºæ™¯
    # target: [A, T, output_dim] - çœŸå®è½¨è¿¹
    
    # è®¡ç®—æ¯ä¸ªåœºæ™¯çš„è”åˆä¼¼ç„¶
    for k in range(K):
        joint_log_prob = âˆ_{i=1}^{A} âˆ_{t=1}^{T} f(p_i^{t}|Î¸_k)
        scene_nll = -joint_log_prob.sum()
    
    # é€‰æ‹©æœ€ä½³åœºæ™¯
    best_scene = argmin(scene_nlls)
    return scene_nlls[best_scene]
```

### Joint Mixture NLL Loss (åœºæ™¯çº§åˆ†ç±»æŸå¤±)
```python
# ä¼˜åŒ–æœ€ä½³åœºæ™¯çš„ç½®ä¿¡åº¦
scene_log_probs = F.log_softmax(scene_pi, dim=0)
classification_loss = -scene_log_probs[best_scene_idx]
```

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### 1. **è®­ç»ƒQCNextæ¨¡å‹**

```bash
python train_qcnext.py \
    --root /path/to/argoverse_v2 \
    --num_joint_modes 6 \
    --hidden_dim 128 \
    --max_epochs 64 \
    --train_batch_size 4 \
    --devices 1 \
    --output_head
```

### 2. **ä¸»è¦å‚æ•°è¯´æ˜**

```bash
# QCNextç‰¹æœ‰å‚æ•°
--num_joint_modes 6        # Kä¸ªè”åˆåœºæ™¯æ•°é‡
--max_agents 64           # æœ€å¤§æ”¯æŒæ™ºèƒ½ä½“æ•°é‡ï¼ˆä»£ç ä¸­è®¾ç½®ï¼‰

# ç½‘ç»œæ¶æ„å‚æ•°
--hidden_dim 128          # éšè—å±‚ç»´åº¦
--num_dec_layers 2        # è§£ç å™¨å±‚æ•°
--num_heads 8             # æ³¨æ„åŠ›å¤´æ•°
--dropout 0.1             # Dropoutç‡

# è®­ç»ƒå‚æ•°
--lr 5e-4                 # å­¦ä¹ ç‡
--weight_decay 1e-4       # æƒé‡è¡°å‡
--gradient_clip_val 1.0   # æ¢¯åº¦è£å‰ªï¼ˆè‡ªåŠ¨æ·»åŠ ï¼‰
```

### 3. **ä»QCNetè¿ç§»**

å¦‚æœä½ æœ‰QCNetçš„æ£€æŸ¥ç‚¹ï¼Œå¯ä»¥è¿™æ ·è¿ç§»ï¼š

```python
# 1. åŠ è½½QCNetæ£€æŸ¥ç‚¹
qcnet_ckpt = torch.load('qcnet_checkpoint.ckpt')

# 2. åˆå§‹åŒ–QCNext
qcnext = QCNext(num_joint_modes=6, ...)

# 3. è¿ç§»ç¼–ç å™¨æƒé‡ï¼ˆå®Œå…¨å…¼å®¹ï¼‰
encoder_state = {k.replace('encoder.', ''): v 
                 for k, v in qcnet_ckpt['state_dict'].items() 
                 if 'encoder' in k}
qcnext.encoder.load_state_dict(encoder_state)

# 4. è§£ç å™¨éœ€è¦é‡æ–°è®­ç»ƒï¼ˆæ¶æ„ä¸åŒï¼‰
```

## ğŸ“ˆ æ€§èƒ½ä¼˜åŠ¿

### 1. **ç†è®ºä¼˜åŠ¿**
- **æ˜¾å¼äº¤äº’å»ºæ¨¡**ï¼šRow-wise attentionæ˜¾å¼å»ºæ¨¡åŒåœºæ™¯å†…æ™ºèƒ½ä½“çš„æœªæ¥äº¤äº’
- **åœºæ™¯çº§ä¸€è‡´æ€§**ï¼šè”åˆé¢„æµ‹ç¡®ä¿å¤šæ™ºèƒ½ä½“è½¨è¿¹çš„å…¨å±€ä¸€è‡´æ€§
- **æ›´ä¸°å¯Œçš„æ¨¡å¼**ï¼šKä¸ªè”åˆåœºæ™¯æ¯”å•æ™ºèƒ½ä½“å¤šæ¨¡æ€æ›´å…·è¡¨è¾¾åŠ›

### 2. **å®éªŒç»“æœ**ï¼ˆè®ºæ–‡æ•°æ®ï¼‰
```
Argoverse 2 Multi-Agent Challenge:
- minADE: QCNetå•æ™ºèƒ½ä½“ â†’ QCNextè”åˆé¢„æµ‹ (æå‡)
- minFDE: åœºæ™¯çº§ä¼˜åŒ–å¸¦æ¥æ›´å¥½çš„ç»ˆç‚¹é¢„æµ‹
- é¦–æ¬¡è¯æ˜ï¼šè”åˆé¢„æµ‹åœ¨è¾¹é™…æŒ‡æ ‡ä¸Šä¹Ÿèƒ½è¶…è¶Šè¾¹é™…é¢„æµ‹
```

## ğŸ”§ ä»£ç ç»“æ„

```
QCNextå®ç°æ–‡ä»¶:
â”œâ”€â”€ modules/qcnext_decoder.py          # Multi-Agent DETRè§£ç å™¨
â”œâ”€â”€ losses/joint_nll_loss.py           # è”åˆæŸå¤±å‡½æ•°
â”œâ”€â”€ predictors/qcnext.py               # QCNextä¸»é¢„æµ‹å™¨
â””â”€â”€ train_qcnext.py                    # è®­ç»ƒè„šæœ¬
```

## âš ï¸ æ³¨æ„äº‹é¡¹

### 1. **å†…å­˜å’Œè®¡ç®—å¼€é”€**
```python
# QCNet: [A, M, T, D] â‰ˆ A Ã— 6 Ã— 60 Ã— 4
# QCNext: [K, A, T, D] â‰ˆ 6 Ã— A Ã— 60 Ã— 4
# å½“Aå¾ˆå¤§æ—¶ï¼ŒQCNextçš„æ˜¾å­˜å ç”¨ä¼šæ˜¾è‘—å¢åŠ 
```

### 2. **æ‰¹å¤„ç†å¤§å°**
```bash
# å»ºè®®æ ¹æ®GPUæ˜¾å­˜è°ƒæ•´batch size
# RTX 3090 (24GB): batch_size=2-4
# V100 (32GB): batch_size=4-8
```

### 3. **è®­ç»ƒç¨³å®šæ€§**
```python
# è‡ªåŠ¨æ·»åŠ çš„è®­ç»ƒä¼˜åŒ–æŠ€å·§ï¼š
- gradient_clip_val=1.0      # æ¢¯åº¦è£å‰ª
- EMA updates                # æŒ‡æ•°ç§»åŠ¨å¹³å‡ï¼ˆå¯é€‰ï¼‰
- Warmup scheduler           # å­¦ä¹ ç‡é¢„çƒ­ï¼ˆå¯é€‰ï¼‰
```

## ğŸ”„ ä¸ç°æœ‰ä»£ç çš„å…¼å®¹æ€§

### 1. **æ•°æ®åŠ è½½å™¨**
- âœ… å®Œå…¨å…¼å®¹ç°æœ‰çš„ArgoversV2DataModule
- âœ… æ•°æ®é¢„å¤„ç†æµç¨‹æ— éœ€ä¿®æ”¹

### 2. **è¯„ä¼°æŒ‡æ ‡**
- âœ… è‡ªåŠ¨è½¬æ¢è”åˆé¢„æµ‹ä¸ºè¾¹é™…é¢„æµ‹è¿›è¡Œè¯„ä¼°
- âœ… å¤ç”¨ç°æœ‰çš„minADEã€minFDEç­‰æŒ‡æ ‡

### 3. **å¯è§†åŒ–å·¥å…·**
- âœ… å¯ä»¥å¤ç”¨ç°æœ‰çš„è½¨è¿¹å¯è§†åŒ–ä»£ç 
- ğŸ†• æ–°å¢åœºæ™¯çº§å¯è§†åŒ–åŠŸèƒ½

## ğŸ¯ æ€»ç»“

QCNexté€šè¿‡ä»¥ä¸‹æŠ€æœ¯åˆ›æ–°å®ç°äº†ä»è¾¹é™…åˆ°è”åˆé¢„æµ‹çš„è·ƒå‡ï¼š

1. **Multi-Agent DETRæ¶æ„**ï¼šå€Ÿé‰´DETRçš„æŸ¥è¯¢æœºåˆ¶ï¼Œè®¾è®¡è”åˆåœºæ™¯æŸ¥è¯¢
2. **å››é‡æ³¨æ„åŠ›æœºåˆ¶**ï¼šå…¨æ–¹ä½å»ºæ¨¡æ—¶åºã€åœ°å›¾ã€æ™ºèƒ½ä½“å†…å’Œåœºæ™¯é—´äº¤äº’
3. **åœºæ™¯çº§Winner-Take-All**ï¼šè”åˆä¼˜åŒ–æ‰€æœ‰æ™ºèƒ½ä½“ï¼Œç¡®ä¿å…¨å±€ä¸€è‡´æ€§
4. **æ˜¾å¼æœªæ¥äº¤äº’å»ºæ¨¡**ï¼šä¸å†ä¾èµ–éšå¼çš„å†å²äº¤äº’ï¼Œç›´æ¥å»ºæ¨¡æœªæ¥äº¤äº’

è¿™ä½¿å¾—QCNextæˆä¸ºé¦–ä¸ªåœ¨è”åˆå¤šæ™ºèƒ½ä½“é¢„æµ‹ä»»åŠ¡ä¸Šè¶…è¶Šè¾¹é™…é¢„æµ‹çš„æ¡†æ¶ï¼ğŸ† 